\section{Limitations and Future Work}
As a two node extension of the {\it pageRank} algorithm \cite{page1999pagerank,kleinberg1999}, the {\it bi-partite network random walker} model is an efficient approach to recursively traverse the complex network of articles and editors in Wikipedia. Our results show that model calibration accounts well with ground-truth metrics, and can help characterize how more contributors for each article and better (resp. less) coordination create value (resp. destroy value) in open collaboration. Its very simple input (a binary matrix of contributions) makes it computationally affordable, though not cheap. While applying this algorithm to the entire Wikipedia would be a challenge, it is straightforward to use on small wikis or most open source software projects.

Our results show a first attempt to understand the structure of cooperation and how value is created with a unique model, which can be fully rationalized. The pertinence of the {bi-partite network random walker} for the study of open collaboration shall be confirmed by future work,  to examine in a systematic way some of the results reported in this paper.

Namely, we would have expected that all categories, or at least each category, would exhibit a typical set $(\alpha^{*},\beta^{*})$ of explanatory parameters, which in turn would help gain better understanding of the general structure of collaboration in Wikipedia. Not only our results show that $\beta^{*}$ varies across categories, but can also vary significantly over time for some of the categories we have analyzed. These results require further scrutiny on the evolution of contribution structures and coordination processes, in particular in these specific categories. 

Future work shall also be devoted to further validation, in order to bring quantitative evidence that the model can systematically account for the influence of the coordination feature on value generated by contributions. We have only indirect evidence that coordination is efficient in some categories, like {\it Military History of the US}. An orthogonal way for testing the model would require measuring specifically the level of constructive (resp. destructive) interactions between editors, on articles (e.g. revert actions), and on usual communication channels used by the community of a specific category (e.g., discussion page, IRC channel, mailing list). A negative relationship between $\beta^{*}$ and the amount of positive interactions would further demonstrate the validity of the model.

The structure of the input matrix (i.e., its dimensions and sparsity) requires further scrutiny. We aim to know the sensitivity of $\beta^{*}$ to the total number of editors versus the total number of articles in a category. Presumably coordination  problems are more likely to occur if there are more editors per article. To thoroughly perform these types of tests, we need to investigate more categories of Wikipedia.

The progressive validation process we have described will help gain trust in the model \cite{sornette2007}, and will perhaps allow meaningful out-of-sample predictions of article quality and editors experience rankings, given the structure of cooperation characterized by $\beta^{*}$. Conversely, the {\it bi-partite network random walker} model could be used in the future to set incentives for a reward system that would specifically encourage cooperation. It could also be used as a {\it Suggestbot}\footnote{https://en.wikipedia.org/wiki/User:Suggestbot} to help new editors find friendly Wikipedia categories to start their on-boarding process. This is a reverse approach from current on-boarding practices, where an interest topic is first chosen and then an edit is made in basically a random-chosen environment.

%It remains unclear why the correlation of the method with the grand-truth for editors increases as a convex function of time (see Figure \ref{fig:rhotime} lower panel). We have proposed that it could be the result of the shape of the input matrix $\mathbf{M}$ : usually categories have factors more editors than articles and therefore more information accumulated over time is needed to adequately rank the editors. This hypothesis could be tested further by screening more Wikipedia categories according to a broader ratio of editors and articles. 

%According to the original philosophy of the method of reflections \cite{hidalgo2007}, an additional node type reflecting {\it capabilities} should connect producing and produced entities. In the method of reflections, capabilities are implicit in the model, mainly because they are not observable. In the context of Wikipedia and open collaboration, incorporating capabilities would be more feasible. We can for instance identify what an editor do best to improve an article, among the five metrics (ratio of mark-up to readable text, number of headings, article length, citations per article length, and outgoing intrawiki links) we have used to assess the quality of an article.

%We believe there are two further directions to improve our results. First, we have followed the philosophy of the method of reflections that aims at ranking countries in the world economy. However, the bi-partite network random walker method provides absolute values, which might have a meaning in the context of open collaboration. In future work, we would like to understand further these absolute values. Second, we took the very simplest information for the input matrix $\mathbf{\mathit{M_{ea}}}$ (i.e. whether an editor has modified a given article, or not). We wonder how the performance of the method might change if richer information is incorporated in the matrix (e.g. number of edits, number of bytes changes). \textcolor{red}{Two exclusive hypotheses could be tested: either the model fits better with richer information, or on the contrary, the model is not as good. In the latter case, we would face a {\it less is more} scenario, which would require elucidating why less rich information accounts better for reality. Or conversely, it could help further understand what ground-truth metrics actually contain richer information, and hence, help reverse engineer most relevant direct measures of editor expertise and article quality.}



%A future direction is to explore ways to improve the correlation and the predictive power of the algorithm. At the moment we must calibrate $alpha$ and $beta$ for a category before being able to make predictions. If we could relate $alpha$ and $beta$ to another known parameter then one could start making predictions about the performance of editors and articles.

%We only look at the ranking not at the real quality/expertise values ? Can we learn more the real values about the gap between articles/editors ?

%{\bf [initially in discussion but we have not figure to support this point]} : When we use $\mathbf{M}$ %which is a binary version of $\mathbf{\hat{M}}$ we achieve better results. Knowing that editor touched an article, is more informative than knowing the edit count.  Wikipedia even acknowledges its {\it editcountitis, Compteurd√©dite} with the essay \cite{editcountitis}Wikipedia has never been explicitly gamified, but some editors are immediately attracted to tracking their performance. This leaves us with an overused, and perverse-incentive metric. In fact what we have shown is that edit truly is meaningless when it comes to predicting editor investment and quality. This is a departure from the economics domain, where the best fits for GDP are only in the positive / positive $\alpha$-$\beta$ quadrant.In the cases where maximizing $\alpha$, $\beta$ solution spaces are linear we get a kind of single variable characteristic of a category. 
